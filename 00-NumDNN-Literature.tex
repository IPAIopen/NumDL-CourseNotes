\documentclass[12pt,fleqn]{beamer}

\input{beamerStyle.tex}
\input{abbrv.tex}


\title[Literature]{Literature}
\subtitle{Numerical Methods for Deep Learning}
\date{}

\begin{document}

\makebeamertitle

\begin{frame}
	\frametitle{Selected Literature}
	
	\begin{itemize}
		\item surveys on deep learning: \cite{bengio2009learning,lecun2015deep}
		\item some important works in deep learning: \cite{Rosenblatt1958,Rumelhart1986,LeCun1990,HuangEtAl2006,RainaEtAl2009,KrizhevskySutskeverHinton2012,IoffeSzegedy2015,he2016deep,he2016identity,UlyanovEtAl2016,LiEtAl2017},
		\item applications of deep learning: natural language processing~\cite{CollobertEtAl2011,BordesEtAl2014,JeanEtAl2014}, image processing~\cite{LeCun1990,KrizhevskySutskeverHinton2012}, speech processing~\cite{hinton2012deep}
		\item approximation theory: \cite{Cybenko1989,HornikEtAl1989}
		\item ODE/PDE-inspired approaches to deep learning: \cite{E2017, HaberRuthotto2017,ChangEtAl2017Reversible,RuthottoHaber2018}
		\item optimization: ~\cite{RobbinsMonro1951,GoPe1973,GoPe03,OLearyRust2013,Bottou2012,Bertsekas2015,bottou2016optimization,Onken2020DO,NewmanEtAl2020}
		\item numerical methods: overview \cite{AscherGreif2011}, optimization \cite{NocedalWright2006,BoydVandenberghe2004,Beck2014}, linear algebra~\cite{Saad2003,HansenNagyOLeary2006}, differential equations~\cite{AscherPetzold1998,Ascher2010}, optimal control~\cite{BorzSchulz2012}
		\item classical work on adjoints ($\approx$ backpropagation) \cite{bliss1919}
		\item inverse problems: \cite{Hansen1998,Vogel2002,Hansen2010}
	\end{itemize}
\end{frame}


\begin{frame}[allowframebreaks]
	\frametitle{References}
 \bibliographystyle{abbrv}
\bibliography{NumDNN}

\end{frame}

\end{document}






